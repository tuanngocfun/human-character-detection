{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import re\n",
    "\n",
    "# Load VGG16 model for feature extraction\n",
    "base_model = VGG16(weights='imagenet')\n",
    "model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc1').output)\n",
    "\n",
    "def load_and_process_image(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    img = cv2.resize(img, (224, 224))\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def extract_features(img):\n",
    "    feature = model.predict(img)\n",
    "    return np.squeeze(feature)\n",
    "\n",
    "def move_duplicates(duplicates_dict, target_dir):\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    for key, values in duplicates_dict.items():\n",
    "        for file_path in values:\n",
    "            try:\n",
    "                shutil.move(file_path, target_dir)\n",
    "            except Exception as e:\n",
    "                print(f\"Could not move image {file_path}. Error: {e}\")\n",
    "\n",
    "src_dir = '../../compare-method-for-filtering-out-duplicated-image/image-source2'\n",
    "\n",
    "# Calculate highest_existed_number based on existing directories\n",
    "trial_pattern = '../../faiss/duplicate/trial*'\n",
    "trial_list = glob.glob(trial_pattern)\n",
    "highest_existed_number = max([int(re.search(r'trial(\\d+)', trial).group(1)) for trial in trial_list], default=0)\n",
    "\n",
    "features = []\n",
    "paths = []\n",
    "for filename in os.listdir(src_dir):\n",
    "    if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "        try:\n",
    "            image_path = os.path.join(src_dir, filename)\n",
    "            img = load_and_process_image(image_path)\n",
    "            feature = extract_features(img)\n",
    "            features.append(feature)\n",
    "            paths.append(image_path)\n",
    "            print(f\"Processed image {filename}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not process image {filename}. Error: {e}\")\n",
    "\n",
    "features = np.array(features)\n",
    "cosine_similarities = 1 - squareform(pdist(features, metric='cosine'))\n",
    "\n",
    "silhouette_scores = []\n",
    "thresholds = np.linspace(0.0, 1.0, 100)\n",
    "for threshold in thresholds:\n",
    "    # Apply a threshold to the similarity matrix to create a binary adjacency matrix\n",
    "    adjacency_matrix = (cosine_similarities > threshold).astype(int)\n",
    "\n",
    "    # Apply clustering using KMeans\n",
    "    n_clusters = 2  \n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(features)\n",
    "\n",
    "    # Calculate silhouette score\n",
    "    score = silhouette_score(features, kmeans.labels_)\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "optimal_threshold_index = np.argmax(silhouette_scores)\n",
    "optimal_threshold = thresholds[optimal_threshold_index]\n",
    "print(f\"Optimal cosine similarity threshold: {optimal_threshold}\")\n",
    "\n",
    "indices = np.where(cosine_similarities > optimal_threshold)\n",
    "duplicates_dict = defaultdict(list)\n",
    "handled_images = set()\n",
    "for i in range(len(indices[0])):\n",
    "    if indices[0][i] < indices[1][i]:\n",
    "        img1 = paths[indices[0][i]]\n",
    "        img2 = paths[indices[1][i]]\n",
    "        if img2 not in handled_images:\n",
    "            duplicates_dict[img1].append(img2)\n",
    "            handled_images.add(img2)\n",
    "\n",
    "save_dir = f'../../faiss/duplicate/trial{highest_existed_number+1}/silhouette_score'\n",
    "\n",
    "print(f\"Duplicates will be moved to: {save_dir}\")\n",
    "print(f\"Found {sum([len(val) for val in duplicates_dict.values()])} duplicates.\")\n",
    "\n",
    "move_duplicates(duplicates_dict, save_dir)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
